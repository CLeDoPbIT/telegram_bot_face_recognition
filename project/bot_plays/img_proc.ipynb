{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model filename: C:/Users/User/Documents/Py projects/bot_plays/20170512-110547/20170512-110547.pb\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "PYSOLR_PATH = \"C:/Users/User/Documents/Py projects/bot_plays\"\n",
    "if not PYSOLR_PATH in sys.path:\n",
    "    sys.path.append(PYSOLR_PATH)\n",
    "\n",
    "## обернуть все в функцию, чтобы просто импортнуть эту грязь в боте и юзать через импорт\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import facenet1\n",
    "import warnings\n",
    "import detect_face1\n",
    "import cv2\n",
    "import argparse\n",
    "import os\n",
    "import os.path\n",
    "import itertools\n",
    "import six.moves as sm\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import PIL.Image\n",
    "import imutils\n",
    "try:\n",
    "    from cStringIO import StringIO as BytesIO\n",
    "except ImportError:\n",
    "    from io import BytesIO\n",
    "\n",
    "\n",
    "#images\n",
    "import imutils\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from scipy import ndimage, misc\n",
    "from skimage import data\n",
    "\n",
    "# classifiers metrics, encoder, optimize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# output\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "#analyse util\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "## PATHS\n",
    "\n",
    "saved_SVM_weights = 'C:/Users/User/Documents/Py projects/bot_plays/svm_model.sav'\n",
    "saved_encoder_classes_path = 'C:/Users/User/Documents/Py projects/bot_plays/women_encoder_classes.npy'\n",
    "#saved_encoder_answ_classes_path = 'drive/face2/women_encoder_answ_classes.npy' make later\n",
    "face_net_prep_path = 'C:/Users/User/Documents/Py projects/bot_plays/20170512-110547/20170512-110547.pb'\n",
    "detect_face_prep_path = 'C:/Users/User/Documents/Py projects/bot_plays/align'\n",
    "\n",
    "## METADATA\n",
    "class IdentityMetadata():\n",
    "    def __init__(self, base, name, file):\n",
    "        # dataset base directory\n",
    "        self.base = base\n",
    "        # identity name\n",
    "        self.name = name\n",
    "        # image file name\n",
    "        self.file = file\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.image_path()\n",
    "\n",
    "    def image_path(self):\n",
    "        return os.path.join(self.base, self.name, self.file) \n",
    "    \n",
    "### ==========================================================FUNCTIONS\n",
    "\n",
    "def getFace(img):\n",
    "    img_size = np.asarray(img.shape)[0:2]\n",
    "    bounding_boxes = []\n",
    "    _ = []\n",
    "    faces = None\n",
    "    minsize = 20\n",
    "    threshold = [0.6, 0.7, 0.7]\n",
    "    factor = 0.709\n",
    "    margin = 44\n",
    "    input_image_size = 160\n",
    "    bounding_boxes, _ = detect_face1.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n",
    "    if not len(bounding_boxes) == 0:\n",
    "        for face in bounding_boxes:\n",
    "            if face[4] > 0.50:\n",
    "                det = np.squeeze(face[0:4])\n",
    "                bb = np.zeros(4, dtype=np.int32)\n",
    "                bb[0] = np.maximum(det[0] - margin / 2, 0)\n",
    "                bb[1] = np.maximum(det[1] - margin / 2, 0)\n",
    "                bb[2] = np.minimum(det[2] + margin / 2, img_size[1])\n",
    "                bb[3] = np.minimum(det[3] + margin / 2, img_size[0])\n",
    "                cropped = img[bb[1]:bb[3], bb[0]:bb[2], :]\n",
    "                resized = cv2.resize(cropped, (input_image_size,input_image_size),interpolation=cv2.INTER_CUBIC)\n",
    "                prewhitened = facenet1.prewhiten(resized)\n",
    "                faces = getEmbedding(prewhitened)[0]\n",
    "    return faces\n",
    "\n",
    "  \n",
    "def load_image(path):\n",
    "    img = cv2.imread(path, 1)\n",
    "    # OpenCV loads images with color channels\n",
    "    # in BGR order. So we need to reverse them\n",
    "    return img[...,::-1]\n",
    "  \n",
    "def getEmbedding(resized):\n",
    "    reshaped = resized.reshape(-1,input_image_size,input_image_size,3)\n",
    "    feed_dict = {images_placeholder: reshaped, phase_train_placeholder: False}\n",
    "    embedding = sess.run(embeddings, feed_dict=feed_dict)\n",
    "    return embedding\n",
    "    \n",
    "def load_metadata(path):\n",
    "    metadata = []\n",
    "    for i in os.listdir(path):\n",
    "        for f in os.listdir(os.path.join(path, i)):\n",
    "            metadata.append(IdentityMetadata(path, i, f))\n",
    "    return np.array(metadata)\n",
    "\n",
    "### ===========================================================PLOTING\n",
    "def load_metadata_exp(path):\n",
    "    metadata = []\n",
    "    for i in os.listdir(path):\n",
    "        metadata.append(os.path.join(path, i))\n",
    "    return np.array(metadata)\n",
    "  \n",
    "# some global vars\n",
    "minsize = 20\n",
    "threshold = [0.6, 0.7, 0.7]\n",
    "factor = 0.709\n",
    "margin = 44\n",
    "input_image_size = 160\n",
    "\n",
    "# tf session start\n",
    "sess = tf.Session()\n",
    "\n",
    "# read pnet, rnet, onet models from align directory and files are det1.npy, det2.npy, det3.npy\n",
    "pnet, rnet, onet = detect_face1.create_mtcnn(sess, detect_face_prep_path) #'drive/face2/align')\n",
    "\n",
    "# read 20170512-110547 model file downloaded from https://drive.google.com/file/d/0B5MzpY9kBtDVZ2RpVDYwWmxoSUk\n",
    "facenet1.load_model(face_net_prep_path) #\"drive/face2/20170512-110547/20170512-110547.pb\")\n",
    "\n",
    "# Get input and output tensors\n",
    "images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "embedding_size = embeddings.get_shape()[1]\n",
    "\n",
    "# load prelearned svm\n",
    "SVM = joblib.load(saved_SVM_weights)\n",
    "\n",
    "## ================== SVC predict\n",
    "# answ photos\n",
    "meta_exp = load_metadata_exp('C:/Users/User/Documents/Py projects/bot_plays/Women_ans')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = joblib.load(saved_encoder_classes_path)\n",
    "\n",
    "def class_detector(image):\n",
    "    resized_image = imutils.resize(image,width=1000) #Картинка для поиска\n",
    "    face = getFace(resized_image)\n",
    "    if not face is None:  \n",
    "        prediction = SVM.predict([face])\n",
    "        identity = encoder.inverse_transform(prediction)[0]\n",
    "\n",
    "\n",
    "        for i in meta_exp:\n",
    "            if( identity == i.rpartition('/')[2].partition('.')[0]):\n",
    "                good_image = i\n",
    "                break\n",
    "\n",
    "        good_image_load = load_image(good_image)\n",
    "        #plt.imshow(good_image_load)\n",
    "        answer = (\"You Recognized as \" + example_identity, good_image_load)\n",
    "    else:\n",
    "        answer = \"Unfortunatly, I think there are no faces! Could You give me another photo?\"\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
